import cv2
import dataclasses
from typing import Dict, List, Tuple, Any
import numpy as np
import copy
import os
import requests
import boto3
import logging
import torchvision

from .common import BaseObjectDetector

logger = logging.getLogger(__name__)
logger.setLevel(logging.DEBUG)

from typing import Callable


def draw_boxes(boxes, classes, image, color):
    image = cv2.cvtColor(np.asarray(image), cv2.COLOR_BGR2RGB)

    for i, box in enumerate(boxes):
        cv2.rectangle(
            image,
            (int(box[0]), int(box[1])),
            (int(box[2]), int(box[3])),
            color, 2
        )

        cv2.putText(image, classes[i], (int(box[0]), int(box[1]-5)),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2,
                    lineType=cv2.LINE_AA)

    return image
 

# @dataclass
# class TorchVisionModel:
#     model_init_function: Callable[[], torchvision.models.detection.faster_rcnn.FasterRCNN]
#     model_weights: torchvision.models.detection.WeightsEnum


@dataclasses.dataclass
class FasterRCNNMobileNetDetector(BaseObjectDetector):
    bounding_box_color: Tuple[int, int, int] = (255, 0, 0)
    detector_name: str = "faster_rcnn_mobilenet"
    detector_version: str = "0.0.1"

    model_init_function = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2
    model_weights = torchvision.models.detection.FasterRCNN_MobileNet_V3_Large_FPN_Weights.COCO_V1

    def __post_init__(self):
        self.confidence_limit = 0.85

        self.dataset_labels = self.model_weights.meta["categories"]

        # https://debuggercafe.com/using-any-torchvision-pretrained-model-as-backbone-for-pytorch-faster-rcnn/
        # model = torchvision.models.detection.fasterrcnn_mobilenet_v3_large_fpn(weights=torchvision.models.detection.FasterRCNN_MobileNet_V3_Large_FPN_Weights.COCO_V1)
        # model = torchvision.models.detection.fasterrcnn_resnet50_fpn_v2(weights=torchvision.models.detection.FasterRCNN_ResNet50_FPN_V2_Weights.COCO_V1)

        self.model = self.model_init_function(
            weights=self.model_weights
        )

        self.model.eval().to('cpu')

        self.transform_image = torchvision.transforms.Compose([
            torchvision.transforms.ToTensor(),
        ])

    def process(self, image: np.array, **kwargs) -> List["ProcessedImage"]:
        # transform the image to tensor
        transformed_image = self.transform_image(image)
        transformed_image = transformed_image.unsqueeze(0) # add a batch dimension

        outputs = self.model(transformed_image) # get the predictions on the image
        # print(outputs)
        assert len(outputs) == 1
        boxes, labels, scores = [outputs[0][x] for x in ['boxes', 'labels', 'scores']]

        mask = scores >= self.confidence_limit

        boxes, labels, scores = [x.detach().cpu().numpy()[mask] for x in [boxes, labels, scores]]

        label_names = [self.dataset_labels[i] for i in labels]

        image = draw_boxes(boxes, label_names, image, self.bounding_box_color)

        object_names = set(label_names)
        label_names_lookup = zip(label_names, boxes)

        from ..records import ProcessedImage
        processed_images = []
        for object_name in object_names:
            object_boxes = [box for label_name, box in label_names_lookup if label_name == object_name]
            processed_images.append(
                ProcessedImage(
                    image=image,
                    object_name=object_name,
                    object_bounding_boxes=[(int(x), int(y), int(w), int(h)) for (x, y, w, h) in object_boxes], 
                    detector_name=self.detector_name,
                    detector_version=self.detector_version,
                    **kwargs
                )
            )
            
        return processed_images
    

 

