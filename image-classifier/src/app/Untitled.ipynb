{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41eb53c-33f1-4bb6-ab06-19fb0a15b1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "428f34cf-03dd-40be-91f0-733270862bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b661f68-00f0-4641-bb81-770b7b159833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5af0585-c387-4475-9a68-39c68d8a636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_kafka_message_delivery(err, msg):\n",
    "    \"\"\" Called once for each message produced to indicate delivery result.\n",
    "    Triggered by poll() or flush(). \"\"\"\n",
    "    if err is not None:\n",
    "        print(f'Message delivery failed: {err}')\n",
    "    else:\n",
    "        print(f'Message delivered to {msg.topic()}. Partition: [{msg.partition()}]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "338fe5cb-e853-4c60-b932-acd9000296b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ImageStreamProcessor:\n",
    "    src_topic: str\n",
    "    src_partition: int\n",
    "    src_avro_schema: fastavro.types.Schema\n",
    "    tgt_topic: str\n",
    "    # tgt_partition: int\n",
    "    tgt_avro_schema: fastavro.types.Schema\n",
    "    kafka_config: dict[str, str]\n",
    "    poll_period_seconds: float = 1.0\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.consumer = Consumer(self.kafka_config)\n",
    "        # self.consumer.subscribe(self.topic)\n",
    "        \n",
    "        self.consumer.assign([\n",
    "            TopicPartition(\n",
    "                self.src_topic,\n",
    "                self.src_partition\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.producer = Producer(self.kafka_config)\n",
    "\n",
    "\n",
    "    def _consume(self):\n",
    "    \n",
    "        while True:\n",
    "            msg = self.consumer.poll(timeout=self.poll_period_seconds)\n",
    "            if msg is None: continue\n",
    "\n",
    "            if msg.error():\n",
    "                if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                    # End of partition event\n",
    "                    sys.stderr.write('%% %s [%d] reached end at offset %d\\n' % (msg.topic(), msg.partition(), msg.offset()))\n",
    "                elif msg.error():\n",
    "                    raise KafkaException(msg.error())\n",
    "            else:\n",
    "                proccessed_images = self.process_message(msg)\n",
    "                self.write_processed_images(proccessed_images)\n",
    "                \n",
    "\n",
    "    def consume(self):\n",
    "        try:\n",
    "            self._consume()\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error occurred while running Kafka Consumer. topic: {self.src_topic} partition: {self.src_partition} \", e)\n",
    "        finally:\n",
    "            self.consumer.close()\n",
    "            self.producer.flush()\n",
    "\n",
    "    \n",
    "    def process_message(self, msg) -> list[ProcessedImage]:\n",
    "    \n",
    "        records = self.deserialize_avro(\n",
    "            msg.value()\n",
    "        )\n",
    "        assert len(records) <= 1\n",
    "        record = records[0]\n",
    "        \n",
    "        image = RawImageRecord(id=msg.key(), **record)\n",
    "        processed_images = image.process_image()\n",
    "\n",
    "        return processed_images\n",
    "       \n",
    "        # display(Image.fromarray(processed_images[0].image))\n",
    "        # print(len(processed_images[0].object_bounding_boxes))\n",
    "\n",
    "    def write_processed_images(self, processed_images: list[ProcessedImage]):\n",
    "        for img in processed_images:\n",
    "            avro_bytes = self.serialize_avro([img.to_record()])\n",
    "\n",
    "            self.producer.produce(\n",
    "                topic=self.tgt_topic,\n",
    "                value=avro_bytes,\n",
    "                key=img.id,\n",
    "                on_delivery=log_kafka_message_delivery\n",
    "            )\n",
    "    \n",
    "        # producer.flush()\n",
    "    \n",
    "        # producer.poll(0)\n",
    "\n",
    "    \n",
    "    def serialize_avro(self, objs: list) -> bytes:\n",
    "        bytes_writer = io.BytesIO()\n",
    "    \n",
    "        fastavro.writer(bytes_writer, \n",
    "                        schema=self.tgt_avro_schema, \n",
    "                        records=objs\n",
    "        )\n",
    "\n",
    "        return bytes_writer.getvalue()\n",
    "        \n",
    "\n",
    "    def deserialize_avro(self, avro_bytes: bytes) -> list[AvroMessage]:\n",
    "        with io.BytesIO(avro_bytes) as bytes_io:\n",
    "            reader = fastavro.reader(bytes_io, self.src_avro_schema)\n",
    "            return [msg for msg in reader]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac34d30e-4e29-4ccd-b056-c8119daeadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# consumer = ImageStreamProcessor(\n",
    "#     src_topic=raw_video_frames_topic_name,\n",
    "#     src_partition=0,\n",
    "#     src_avro_schema=parse_schema(json.loads(raw_image_avro_schema)),\n",
    "#     tgt_topic=processed_video_frames_topic_name,\n",
    "#     tgt_avro_schema=parse_schema(json.loads(processed_image_avro_schema)),\n",
    "#     kafka_config=kafka_config\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b74de574-a5f4-41e9-baaf-59267dac7b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consumer.consume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68ea49c1-3392-4433-ba84-22b089d5de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, Producer, TopicPartition, KafkaException, KafkaError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a92bea2-619e-4062-adfc-549445a7ebde",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 22\u001b[0m\n\u001b[1;32m     17\u001b[0m futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     18\u001b[0m     executor\u001b[38;5;241m.\u001b[39msubmit(\u001b[38;5;28;01mlambda\u001b[39;00m processor: processor\u001b[38;5;241m.\u001b[39mconsume(), processor)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m processors\n\u001b[1;32m     20\u001b[0m ]\n\u001b[0;32m---> 22\u001b[0m completed_futures, uncompleted_futures \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFIRST_EXCEPTION\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m uncompleted_futures:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/concurrent/futures/_base.py:305\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    303\u001b[0m     waiter \u001b[38;5;241m=\u001b[39m _create_and_install_waiters(fs, return_when)\n\u001b[0;32m--> 305\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m fs:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 16\u001b[0m\n\u001b[1;32m      1\u001b[0m src_partitions \u001b[38;5;241m=\u001b[39m Consumer(kafka_config)\u001b[38;5;241m.\u001b[39mlist_topics()\u001b[38;5;241m.\u001b[39mtopics[raw_video_frames_topic_name]\u001b[38;5;241m.\u001b[39mpartitions\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m      3\u001b[0m processors \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     ImageStreamProcessor(\n\u001b[1;32m      5\u001b[0m         src_topic\u001b[38;5;241m=\u001b[39mraw_video_frames_topic_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;129;01min\u001b[39;00m src_partitions\n\u001b[1;32m     14\u001b[0m ]\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc_partitions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mprocessors\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompleted_futures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muncompleted_futures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_when\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFIRST_EXCEPTION\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1133\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "src_partitions = Consumer(kafka_config).list_topics().topics[raw_video_frames_topic_name].partitions.keys()\n",
    "\n",
    "processors = [\n",
    "    ImageStreamProcessor(\n",
    "        src_topic=raw_video_frames_topic_name,\n",
    "        src_partition=0,\n",
    "        src_avro_schema=parse_schema(json.loads(raw_image_avro_schema)),\n",
    "        tgt_topic=processed_video_frames_topic_name,\n",
    "        tgt_avro_schema=parse_schema(json.loads(processed_image_avro_schema)),\n",
    "        kafka_config=kafka_config\n",
    "    )\n",
    "    for partition \n",
    "    in src_partitions\n",
    "]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=len(src_partitions)) as executor:\n",
    "    futures = [\n",
    "        executor.submit(lambda processor: processor.consume(), processor)\n",
    "        for processor in processors\n",
    "    ]\n",
    "\n",
    "    completed_futures, uncompleted_futures = wait(\n",
    "        futures,\n",
    "        return_when=FIRST_EXCEPTION\n",
    "    )\n",
    "\n",
    "    for future in uncompleted_futures:\n",
    "        future.result()\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
